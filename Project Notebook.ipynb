{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages used in the notebook. \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change working directory.\n",
    "os.chdir('C:\\\\Users\\\\jday1\\\\Data Tools 1\\\\Project\\\\new folder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving year 2014 as .csv for later use\n",
      "Saving year 2015 as .csv for later use\n",
      "Saving year 2016 as .csv for later use\n",
      "Saving year 2017 as .csv for later use\n"
     ]
    }
   ],
   "source": [
    "#Import Raw FBI data and convert to Dataframe. Output '.csv' files for \"possible\" later use.\n",
    "years = [2014,2015,2016,2017]\n",
    "\n",
    "for year in years:\n",
    "    print('Saving year ' + str(year) + ' as .csv for later use')\n",
    "    if year == 2014:\n",
    "        file_name=\"Human_Trafficking_Offenses_and_Clearances_by_State_2014.csv\"\n",
    "        ht_offenses_clearing_2014_df = pd.read_excel(\"Table_2_Human_Trafficking_Offenses_and_Clearances_by_State_2014.xlsx\")\n",
    "        ht_offenses_clearing_2014_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "    elif year == 2015:\n",
    "        file_name=\"Human_Trafficking_Offenses_and_Clearances_by_State_\" + str(year) + \".csv\"\n",
    "        ht_offenses_clearing_2015_df = pd.read_excel(\"table-1_Human_Trafficking_Offenses_and_Clearances_by_State_\"+ str(year) + \".xls\")\n",
    "        ht_offenses_clearing_2015_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "    elif year == 2016:\n",
    "        file_name=\"Human_Trafficking_Offenses_and_Clearances_by_State_\" + str(year) + \".csv\"\n",
    "        ht_offenses_clearing_2016_df = pd.read_excel(\"table-1_Human_Trafficking_Offenses_and_Clearances_by_State_\"+ str(year) + \".xls\")\n",
    "        ht_offenses_clearing_2016_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "    elif year == 2017:\n",
    "        file_name=\"Human_Trafficking_Offenses_and_Clearances_by_State_\" + str(year) + \".csv\"\n",
    "        ht_offenses_clearing_2017_df = pd.read_excel(\"table-1_Human_Trafficking_Offenses_and_Clearances_by_State_\"+ str(year) + \".xls\")\n",
    "        ht_offenses_clearing_2017_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column names\n",
    "ht_offenses_clearing_2014_df.columns = [\"state\", \"commercial_sex_act_offense\", \"commercial_sex_act_cleared\", \"commercial_sex_act_cleared_under_18\", \"involuntary_servitude_offense\", \"involuntary_servitude_cleared\", \"involuntary_servitude_cleared_under_18\",\"total_offenses\", \"total_cleared\",\"total_under_18\"]\n",
    "ht_offenses_clearing_2015_df.columns = [\"state\", \"commercial_sex_act_offense\", \"commercial_sex_act_cleared\", \"commercial_sex_act_cleared_under_18\", \"involuntary_servitude_offense\", \"involuntary_servitude_cleared\", \"involuntary_servitude_cleared_under_18\",\"total_offenses\", \"total_cleared\",\"total_under_18\"]\n",
    "ht_offenses_clearing_2016_df.columns = [\"state\", \"commercial_sex_act_offense\", \"commercial_sex_act_cleared\", \"commercial_sex_act_cleared_under_18\", \"involuntary_servitude_offense\", \"involuntary_servitude_cleared\", \"involuntary_servitude_cleared_under_18\",\"total_offenses\", \"total_cleared\",\"total_under_18\"]\n",
    "ht_offenses_clearing_2017_df.columns = [\"state\", \"commercial_sex_act_offense\", \"commercial_sex_act_cleared\", \"commercial_sex_act_cleared_under_18\", \"involuntary_servitude_offense\", \"involuntary_servitude_cleared\", \"involuntary_servitude_cleared_under_18\",\"total_offenses\", \"total_cleared\",\"total_under_18\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the rows with NaNs. I did not use df.dropna() because I know the static rows that need to be dropped. \n",
    "ht_offenses_clearing_2014_df = ht_offenses_clearing_2014_df.drop([0, 1, 2, 3])\n",
    "ht_offenses_clearing_2015_df = ht_offenses_clearing_2015_df.drop([0, 1, 2, 3])\n",
    "ht_offenses_clearing_2016_df = ht_offenses_clearing_2016_df.drop([0, 1, 2, 3])\n",
    "ht_offenses_clearing_2017_df = ht_offenses_clearing_2017_df.drop([0, 1, 2, 3,51])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want a single view of all the data. Thus I will combine the data eventually.\n",
    "# so I am adding a year column to all dfs to note what year the data is from when combining dfs.\n",
    "ht_offenses_clearing_2014_df['year'] = 2014\n",
    "ht_offenses_clearing_2015_df['year'] = 2015\n",
    "ht_offenses_clearing_2016_df['year'] = 2016\n",
    "ht_offenses_clearing_2017_df['year'] = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving year 2014\n",
      "Saving year 2015\n",
      "Saving year 2016\n",
      "Saving year 2017\n"
     ]
    }
   ],
   "source": [
    "#Saving new dfs to csv created above\n",
    "for year in years:\n",
    "    print('Saving year ' + str(year))\n",
    "    if year == 2014:\n",
    "        file_name=\"Human_Trafficking_Offenses_and_Clearances_by_State_2014.csv\"\n",
    "        ht_offenses_clearing_2014_df = pd.read_excel(\"Table_2_Human_Trafficking_Offenses_and_Clearances_by_State_2014.xlsx\")\n",
    "        ht_offenses_clearing_2014_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "    elif year == 2015:\n",
    "        file_name=\"Human_Trafficking_Offenses_and_Clearances_by_State_\" + str(year) + \".csv\"\n",
    "        ht_offenses_clearing_2015_df = pd.read_excel(\"table-1_Human_Trafficking_Offenses_and_Clearances_by_State_\"+ str(year) + \".xls\")\n",
    "        ht_offenses_clearing_2015_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "    elif year == 2016:\n",
    "        file_name=\"Human_Trafficking_Offenses_and_Clearances_by_State_\" + str(year) + \".csv\"\n",
    "        ht_offenses_clearing_2016_df = pd.read_excel(\"table-1_Human_Trafficking_Offenses_and_Clearances_by_State_\"+ str(year) + \".xls\")\n",
    "        ht_offenses_clearing_2016_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "    elif year == 2017:\n",
    "        file_name=\"Human_Trafficking_Offenses_and_Clearances_by_State_\" + str(year) + \".csv\"\n",
    "        ht_offenses_clearing_2017_df = pd.read_excel(\"table-1_Human_Trafficking_Offenses_and_Clearances_by_State_\"+ str(year) + \".xls\")\n",
    "        ht_offenses_clearing_2017_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the dfs for a single df view\n",
    "frames = [ht_offenses_clearing_2014_df,ht_offenses_clearing_2015_df,ht_offenses_clearing_2016_df,ht_offenses_clearing_2017_df]\n",
    "ht_offenses_clearing_4_years_df = pd.concat(frames)\n",
    "\n",
    "file_name = \"Human_Trafficking_Offenses_and_Clearances_by_State_2014_to_2017.csv\"\n",
    "ht_offenses_clearing_4_years_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
